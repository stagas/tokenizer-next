<h1 align="center">tokenizer-next</h1>

<p align="center">
iterator based tokenizer for writing parsers
</p>

<p align="center">
   <a href="#install">        ğŸ”§ <strong>Install</strong></a>
 Â· <a href="#example">        ğŸ§© <strong>Example</strong></a>
 Â· <a href="#api">            ğŸ“œ <strong>API docs</strong></a>
 Â· <a href="https://github.com/stagas/tokenizer-next/releases"> ğŸ”¥ <strong>Releases</strong></a>
 Â· <a href="#contribute">     ğŸ’ªğŸ¼ <strong>Contribute</strong></a>
 Â· <a href="https://github.com/stagas/tokenizer-next/issues">   ğŸ–ï¸ <strong>Help</strong></a>
</p>

***

## Install

```sh
$ npm i tokenizer-next
```

## What is this?

A tokenizer for writing parsers based on RegExp's [named groups](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions/Groups_and_Ranges#using_named_groups) as returned, for example, by [`String.prototype.matchAll()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/matchAll).

> For a more advanced version of this, check out [lexer-next](https://github.com/stagas/lexer-next) which includes methods for writing [Recursive descent parsers](https://en.wikipedia.org/wiki/Recursive_descent_parser).

## Example

See [TokenizerFactory](#tokenizerfactory).

## API

<!-- Generated by documentation.js. Update this documentation by updating the source code. -->

#### Table of Contents

*   [createTokenizer](#createtokenizer)
    *   [Parameters](#parameters)
*   [TokenizerFactory](#tokenizerfactory)
    *   [Parameters](#parameters-1)
*   [TokenizerCallableIterable](#tokenizercallableiterable)

### createTokenizer

[src/index.ts:19-37](https://github.com/stagas/tokenizer-next/blob/d7ac15bc32521300c55c80a1b8f3952f47e81a67/src/index.ts#L19-L37 "Source code on GitHub")

Create a [TokenizerFactory](#tokenizerfactory) for the given RegExps.

To capture, RegExps must use a [named group](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions/Groups_and_Ranges#using_named_groups).

```ts
const tokenize = createTokenizer(
  /(?<ident>[a-z]+)/, // named groups determine token `group`
  /(?<number>[0-9]+)/
)
```

#### Parameters

*   `regexps` **...[Array](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array)<[RegExp](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/RegExp)>** RegExps to match.

### TokenizerFactory

[src/index.ts:67-67](https://github.com/stagas/tokenizer-next/blob/d7ac15bc32521300c55c80a1b8f3952f47e81a67/src/index.ts#L39-L66 "Source code on GitHub")

Create a [TokenizerCallableIterable](#tokenizercallableiterable) for given input string.

```ts
// using next()
const next = tokenize('hello 123')
console.log(next()) // => {group: 'ident', value: 'hello', index: 0}
console.log(next()) // => {group: 'number', value: '123', index: 6}
console.log(next()) // => undefined

// using for of
for (const token of tokenize('hello 123')) {
  console.log(token)
  // => {group: 'ident', value: 'hello', index: 0}
  // => {group: 'number', value: '123', index: 6}
}

// using spread
const tokens = [...tokenize('hello 123')]
console.log(tokens)
// => [
//   {group: 'ident', value: 'hello', index: 0},
//   {group: 'number', value: '123', index: 6}
// ]
```

Type: function (input: [string](https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String)): [TokenizerCallableIterable](#tokenizercallableiterable)

#### Parameters

*   `input`  The string to tokenize.

### TokenizerCallableIterable

[src/index.ts:74-74](https://github.com/stagas/tokenizer-next/blob/d7ac15bc32521300c55c80a1b8f3952f47e81a67/src/index.ts#L69-L73 "Source code on GitHub")

Can be called to return next <a href="https://github.com/stagas/match-to-token#token">Token</a> or can be used as an
[Iterable](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Iteration_protocols#the_iterable_protocol)
on **for-of** and **spread** operations.

Type: any

## Contribute

[Fork](https://github.com/stagas/tokenizer-next/fork) or
[edit](https://github.dev/stagas/tokenizer-next) and submit a PR.

All contributions are welcome!

## License

MIT Â© 2021
[stagas](https://github.com/stagas)
